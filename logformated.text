import re
import httpx
from fastapi import FastAPI, HTTPException
from fastapi.responses import StreamingResponse
from pydantic import BaseModel, Field
from openai import OpenAI
from duckduckgo_search import DDGS
from datetime import datetime
from typing import AsyncGenerator
import wikipediaapi
import sqlite3
import os
from fastapi.middleware.cors import CORSMiddleware
import logging

# Configure logging
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

app = FastAPI()

# CORS Middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Database Setup
DB_PATH = "data.db"

def init_db():
    with sqlite3.connect(DB_PATH) as conn:
        conn.execute("""
            CREATE TABLE IF NOT EXISTS conversations (
                session_id TEXT NOT NULL,
                role TEXT NOT NULL,
                content TEXT NOT NULL,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        """)
        conn.commit()

init_db()

def load_conversation(session_id: str) -> list[dict]:
    with sqlite3.connect(DB_PATH) as conn:
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        cursor.execute("""
            SELECT role, content FROM conversations
            WHERE session_id = ?
            ORDER BY timestamp
        """, (session_id,))
        return [{"role": row["role"], "content": row["content"]} for row in cursor.fetchall()]

def save_message(session_id: str, role: str, content: str):
    with sqlite3.connect(DB_PATH) as conn:
        conn.execute(
            "INSERT INTO conversations (session_id, role, content) VALUES (?, ?, ?)",
            (session_id, role, content)
        )
        conn.commit()

# Models
class ChatRequest(BaseModel):
    message: str = Field(..., min_length=1, max_length=1000)
    session_id: str = None

# OpenAI Client to Local LLM
client = OpenAI(
    base_url="http://model-runner.docker.internal/engines/llama.cpp/v1",
    api_key="not-needed"
)

# Wikipedia API Client
wiki = wikipediaapi.Wikipedia(
    language='en',
    extract_format=wikipediaapi.ExtractFormat.WIKI,
    user_agent="NOVA/1.0 (jayanthkopparthi595@gmail.com)"
)

# Text Formatting Functions
def clean_and_format_text(text: str) -> str:
    """Clean and properly format text with proper spacing and line breaks."""
    if not text:
        return ""
    
    logger.debug(f"Raw input text: {repr(text)}")
    
    # Pre-clean: Remove non-standard whitespace and invisible characters
    text = re.sub(r'[\u200B-\u200F\uFEFF\s]+', ' ', text)  # Replace zero-width spaces, other invisible chars with single space
    text = re.sub(r'([A-Za-z])\s+(?=[A-Za-z])', r'\1', text)  # Remove spaces between letters within words
    
    # Remove excessive whitespace but preserve intentional line breaks
    text = re.sub(r'[ \t]+', ' ', text)
    text = re.sub(r'\n[ \t]+', '\n', text)
    text = re.sub(r'[ \t]+\n', '\n', text)
    
    # Ensure proper spacing after punctuation
    text = re.sub(r'([.!?])([A-Za-z])', r'\1 \2', text)
    text = re.sub(r'([,;:])([A-Za-z])', r'\1 \2', text)
    
    # Fix concatenated words (e.g., "Icandefinitelyhelpyou" -> "I can definitely help you")
    text = re.sub(r'([a-z])([A-Z])', r'\1 \2', text)
    
    # Add space between number and letter
    text = re.sub(r'(\d)([A-Za-z])', r'\1 \2', text)
    text = re.sub(r'([A-Za-z])(\d)', r'\1 \2', text)
    
    # Ensure proper spacing around emojis
    text = re.sub(r'([.!?,;])([üòä‚ùì‚úÖüîçüåêüëãüéØüìäüí°])', r'\1 \2', text)
    text = re.sub(r'([üòä‚ùì‚úÖüîçüåêüëãüéØüìäüí°])([A-Za-z])', r'\1 \2', text)
    text = re.sub(r'([A-Za-z])([üòä‚ùì‚úÖüîçüåêüëãüéØüìäüí°])', r'\1 \2', text)
    
    # Fix time formatting (e.g., "01: 52PM" -> "01:52 PM")
    text = re.sub(r'(\d+): (\d+)([AP]M)', r'\1:\2 \3', text)
    
    logger.debug(f"Formatted text: {repr(text)}")
    return text.strip()

def format_streaming_chunk(chunk: str) -> str:
    """Format individual streaming chunks to ensure proper spacing."""
    if not chunk:
        return ""
    
    logger.debug(f"Raw chunk: {repr(chunk)}")
    
    # Pre-clean chunk to remove non-standard whitespace and intra-word spaces
    chunk = re.sub(r'[\u200B-\u200F\uFEFF\s]+', ' ', chunk)
    chunk = re.sub(r'([A-Za-z])\s+(?=[A-Za-z])', r'\1', chunk)
    
    # Apply formatting only to complete words or sentences
    formatted = clean_and_format_text(chunk)
    if formatted and not re.search(r'[ \n.!?;:]$', formatted):
        # Avoid adding space mid-word
        if re.search(r'[A-Za-z0-9]$', formatted):
            logger.debug(f"Chunk ends mid-word, no extra space: {repr(formatted)}")
            return formatted
        formatted += ' '
    
    logger.debug(f"Formatted chunk: {repr(formatted)}")
    return formatted

# Assistant Persona
CHAT_SYSTEM_PROMPT = """You are NOVA, a highly accurate, empathetic, and user-friendly personal assistant.  
- Deliver clear, concise, and accurate answers using simple, accessible language to ensure broad understanding.  
- For informational queries, rely on verified, up-to-date facts from reliable sources, avoiding speculation or unconfirmed information.  
- For task-oriented queries, provide detailed, step-by-step guidance with practical, relevant examples tailored to the user's context.  
- If a query is unclear or ambiguous, ask a specific, concise clarifying question to align the response with the user's intent.  
- Use the current date and time, {current_time}, to provide accurate, time-sensitive responses when relevant.  
- Format responses in properly spaced text with appropriate line breaks for readability.
- Use universally supported emojis (e.g., ‚úÖ, ‚ùì) sparingly and with proper spacing for clarity and approachability.  
- Verify all URLs included in responses to ensure they are valid, secure (HTTPS), and directly relevant to the query.  
- If uncertain about a fact or unable to verify information, acknowledge the limitation transparently and recommend trusted sources (e.g., official websites, academic resources) for further details.  
- Avoid fabricating details, making assumptions beyond the provided context, or including irrelevant information.  
- Structure responses using clean markdown syntax with proper spacing:  
  - Use proper line breaks (\\n) for new lines
  - Use bullet points for lists with proper indentation
  - Use headings (e.g., #, ##) for clear section organization
  - Ensure all text is properly spaced between words
- Prioritize readability by using concise sentences, avoiding technical jargon unless necessary, and explaining terms when used.  
"""

WEB_SEARCH_SYSTEM_PROMPT = """You are NOVA, an expert research assistant focused on delivering accurate and reliable information.
- Summarize information from provided sources (e.g., web results, Wikipedia) into a concise, coherent response.
- Prioritize credible sources, citing them clearly (e.g., "Wikipedia states..." or "A web source from [site] reports...").
- Include key facts, dates, definitions, or notable controversies, avoiding unnecessary details.
- If sources conflict, highlight discrepancies and provide a balanced summary.
- Verify all URLs for accessibility and relevance before including them.
- If no reliable sources are found, state this clearly and suggest alternative ways to find information.
- Stay up-to-date with {current_time} for time-sensitive queries.
- Structure responses with clear sections (e.g., "Key Facts," "Sources") for readability.
- Never invent facts, sources, or details. If data is incomplete, acknowledge it.
- Ensure all text has proper spacing between words and proper formatting.
"""

# URL Regex & Checker
url_pattern = re.compile(r'https?://[\w\-./?=&%]+', re.IGNORECASE)

async def check_url(url: str) -> str:
    if url.lower().startswith("javascript:"):
        return f"{url} (unsafe)"
    try:
        async with httpx.AsyncClient(timeout=5.0, follow_redirects=True) as client:
            r = await client.get(url, headers={"User-Agent": "NOVA/1.0"})
            return f"{url} (accessible)" if r.status_code == 200 else f"{url} (status {r.status_code})"
    except Exception as e:
        return f"{url} ({e.__class__.__name__})"

# Chat Endpoint with Memory
@app.post("/chat")
async def chat_stream(request: ChatRequest) -> StreamingResponse:
    current_time = datetime.now().strftime("%B %d, %Y, %I:%M %p %Z")
    session_id = request.session_id or f"sess_{int(datetime.now().timestamp())}_{os.urandom(4).hex()}"

    history = load_conversation(session_id)

    async def event_generator() -> AsyncGenerator[str, None]:
        try:
            accumulated_response = ""
            messages = [
                {"role": "system", "content": CHAT_SYSTEM_PROMPT.format(current_time=current_time)}
            ] + history + [
                {"role": "user", "content": request.message}
            ]

            stream = client.chat.completions.create(
                model="ai/gemma3",
                messages=messages,
                stream=True,
                temperature=0.7,
                max_tokens=2048
            )

            word_buffer = ""
            
            for chunk in stream:
                if chunk.choices[0].delta.content:
                    content = chunk.choices[0].delta.content
                    word_buffer += content
                    accumulated_response += content
                    
                    # Only send complete words or sentences
                    if re.search(r'[ \n.!?;:]', word_buffer) and not re.search(r'[A-Za-z0-9]$', word_buffer):
                        formatted_chunk = format_streaming_chunk(word_buffer)
                        if formatted_chunk:
                            logger.debug(f"Sending chunk: {repr(formatted_chunk)}")
                            yield f"data: {formatted_chunk}\n\n"
                        word_buffer = ""
            
            # Send any remaining content
            if word_buffer.strip():
                formatted_chunk = format_streaming_chunk(word_buffer)
                if formatted_chunk:
                    logger.debug(f"Sending final chunk: {repr(formatted_chunk)}")
                    yield f"data: {formatted_chunk}\n\n"

            final_response = clean_and_format_text(accumulated_response)
            logger.debug(f"Final response: {repr(final_response)}")

            urls = url_pattern.findall(final_response)
            if urls:
                yield f"data: \n\nüîó Links found:\n"
                for url in urls:
                    yield f"data: {await check_url(url)}\n"

            save_message(session_id, "user", request.message)
            save_message(session_id, "assistant", final_response)

            yield f"data: \n\n‚úÖ Continue this chat with session ID: `{session_id}`\n\n"

        except Exception as e:
            error_msg = f"Error: {str(e)}"
            logger.error(f"Stream error: {error_msg}")
            yield f"data: {error_msg}\n\n"
            save_message(session_id, "assistant", f"[System error: {str(e)}]")

    return StreamingResponse(event_generator(), media_type="text/event-stream")

# Web Search with Memory
@app.post("/web_search")
async def web_search(request: ChatRequest) -> StreamingResponse:
    current_time = datetime.now().strftime("%B %d, %Y, %I:%M %p %Z")
    query = request.message
    session_id = request.session_id or f"sess_{int(datetime.now().timestamp())}_{os.urandom(4).hex()}"

    history = load_conversation(session_id)

    async def event_generator() -> AsyncGenerator[str, None]:
        try:
            summary_prompt = WEB_SEARCH_SYSTEM_PROMPT.format(current_time=current_time) + "\n\nAnalyze and summarize the following sources:\n\n"
            all_urls = []

            try:
                dd_results = DDGS().text(query, max_results=5)
                if dd_results:
                    summary_prompt += "=== Web Results (DuckDuckGo) ===\n"
                    for i, r in enumerate(dd_results, 1):
                        summary_prompt += f"{i}. [{r['title']}]({r['href']})\n   {r['body']}\n\n"
                        all_urls.append(r['href'])
            except Exception as e:
                summary_prompt += f"‚ö†Ô∏è Could not fetch web results: {str(e)}\n\n"

            try:
                wiki_page = wiki.page(query)
                if wiki_page.exists():
                    summary_prompt += f"=== Wikipedia Entry: {wiki_page.title} ===\n{wiki_page.summary[:1200]}{'...' if len(wiki_page.summary) > 1200 else ''}\n\n"
                    all_urls.append(wiki_page.fullurl)
                else:
                    summary_prompt += f"‚ö†Ô∏è No Wikipedia page found for '{query}'.\n\n"
            except Exception as e:
                summary_prompt += f"‚ö†Ô∏è Error fetching Wikipedia: {str(e)}\n\n"

            if "‚ö†Ô∏è Could not fetch" in summary_prompt and "=== Wikipedia Entry" not in summary_prompt:
                response = f"‚öå No reliable information found for *{query}* as of {current_time}. Try a different phrasing."
                logger.debug(f"No search results: {repr(response)}")
                yield f"data: {response}\n\n"
                save_message(session_id, "user", query)
                save_message(session_id, "assistant", response)
                yield f"data: \n\nüìå Tip: Be specific and use full terms (e.g., 'climate change effects on oceans').\n"
                yield f"data: ‚úÖ Use session ID: `{session_id}` to continue.\n\n"
                return

            context_messages = [
                {"role": "system", "content": summary_prompt},
                {"role": "user", "content": f"Summarize the key facts about: {query}"}
            ] + history[-4:]

            stream = client.chat.completions.create(
                model="ai/gemma3",
                messages=context_messages,
                stream=True,
                temperature=0.7,
                max_tokens=2048
            )

            accumulated_response = ""
            word_buffer = ""
            
            for chunk in stream:
                if chunk.choices[0].delta.content:
                    content = chunk.choices[0].delta.content
                    word_buffer += content
                    accumulated_response += content
                    
                    if re.search(r'[ \n.!?;:]', word_buffer) and not re.search(r'[A-Za-z0-9]$', word_buffer):
                        formatted_chunk = format_streaming_chunk(word_buffer)
                        if formatted_chunk:
                            logger.debug(f"Sending chunk: {repr(formatted_chunk)}")
                            yield f"data: {formatted_chunk}\n\n"
                        word_buffer = ""
            
            if word_buffer.strip():
                formatted_chunk = format_streaming_chunk(word_buffer)
                if formatted_chunk:
                    logger.debug(f"Sending final chunk: {repr(formatted_chunk)}")
                    yield f"data: {formatted_chunk}\n\n"

            final_response = clean_and_format_text(accumulated_response)
            logger.debug(f"Final response: {repr(final_response)}")

            if all_urls:
                yield f"data: \n\nüîó Verified Sources:\n"
                for url in all_urls:
                    yield f"data: {await check_url(url)}\n"

            yield f"data: \n\nüí° You can ask follow-up questions to go deeper!\n"
            yield f"data: ‚úÖ Continue with session ID: `{session_id}`\n\n"

            save_message(session_id, "user", query)
            save_message(session_id, "assistant", final_response)

        except Exception as e:
            error_msg = f"Search failed: {str(e)}"
            logger.error(f"Search error: {error_msg}")
            yield f"data: {error_msg}\n\n"
            save_message(session_id, "user", query)
            save_message(session_id, "assistant", f"[Error: {str(e)}]")

    return StreamingResponse(event_generator(), media_type="text/event-stream")

# Session Management Endpoints
@app.get("/sessions")
async def list_sessions():
    with sqlite3.connect(DB_PATH) as conn:
        conn.row_factory = sqlite3.Row
        cur = conn.cursor()
        cur.execute("SELECT DISTINCT session_id FROM conversations ORDER BY timestamp")
        sessions = [row["session_id"] for row in cur.fetchall()]
    return {"sessions": sessions}

@app.get("/sessions/{session_id}")
async def get_session(session_id: str):
    with sqlite3.connect(DB_PATH) as conn:
        conn.row_factory = sqlite3.Row
        cur = conn.cursor()
        cur.execute(
            "SELECT role, content, timestamp FROM conversations WHERE session_id = ? ORDER BY timestamp",
            (session_id,)
        )
        rows = cur.fetchall()
        if not rows:
            raise HTTPException(status_code=404, detail="Session not found")
        return {
            "session_id": session_id,
            "messages": [{"role": r["role"], "content": r["content"], "time": r["timestamp"]} for r in rows]
        }

@app.delete("/sessions/{session_id}")
async def delete_session(session_id: str):
    with sqlite3.connect(DB_PATH) as conn:
        cur = conn.cursor()
        cur.execute("SELECT COUNT(*) FROM conversations WHERE session_id = ?", (session_id,))
        count = cur.fetchone()[0]
        if count == 0:
            raise HTTPException(status_code=404, detail="Session not found")
        cur.execute("DELETE FROM conversations WHERE session_id = ?", (session_id,))
        conn.commit()
    return {"message": f"Session {session_id} deleted successfully"}

# Health Check
@app.get("/")
async def root():
    return {"message": "NOVA Assistant is running", "endpoints": ["/chat", "/web_search", "/sessions"]}




DEBUG:app:Raw input text: 'Hello there! üòä It‚Äôs August 18, 2025, 02:17 PM. \n\nI‚Äôm NOVA, your personal assistant. I‚Äôm here to help you with whatever you need ‚Äì answering questions, providing instructions, or just having a conversation.\n\nTo get started, could you tell me: What can I do for you today? ‚ùì'                                      
nova-ai   | DEBUG:app:Formatted text: 'Hellothere! üòä It‚Äôs August 18, 2025, 02:17 PM. I‚Äôm NOVA, yourpersonalassistant. I‚Äômheretohelpyouwithwhateveryouneed ‚Äì answeringquestions, providinginstructions, orjusthavingaconversation. Togetstarted, couldyoutellme: Whatcan Idoforyoutoday? ‚ùì'                                                                        
nova-ai   | DEBUG:app:Final response: 'Hellothere! üòä It‚Äôs August 18, 2025, 02:17 PM. I‚Äôm NOVA, yourpersonalassistant. I‚Äômheretohelpyouwithwhateveryouneed ‚Äì answeringquestions, providinginstructions, orjusthavingaconversation. Togetstarted, couldyoutellme: Whatcan Idoforyoutoday? ‚ùì' 


//// correct one /////
import re
import httpx
from fastapi import FastAPI, HTTPException
from fastapi.responses import StreamingResponse
from pydantic import BaseModel, Field
from openai import OpenAI
from duckduckgo_search import DDGS
from datetime import datetime
from typing import AsyncGenerator
import wikipediaapi
import sqlite3
import os
from fastapi.middleware.cors import CORSMiddleware
import logging

# Configure logging
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

app = FastAPI()

# CORS Middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Database Setup
DB_PATH = "data.db"

def init_db():
    with sqlite3.connect(DB_PATH) as conn:
        conn.execute("""
            CREATE TABLE IF NOT EXISTS conversations (
                session_id TEXT NOT NULL,
                role TEXT NOT NULL,
                content TEXT NOT NULL,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        """)
        conn.commit()

init_db()

def load_conversation(session_id: str) -> list[dict]:
    with sqlite3.connect(DB_PATH) as conn:
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        cursor.execute("""
            SELECT role, content FROM conversations
            WHERE session_id = ?
            ORDER BY timestamp
        """, (session_id,))
        return [{"role": row["role"], "content": row["content"]} for row in cursor.fetchall()]

def save_message(session_id: str, role: str, content: str):
    with sqlite3.connect(DB_PATH) as conn:
        conn.execute(
            "INSERT INTO conversations (session_id, role, content) VALUES (?, ?, ?)",
            (session_id, role, content)
        )
        conn.commit()

# Models
class ChatRequest(BaseModel):
    message: str = Field(..., min_length=1, max_length=1000)
    session_id: str = None

# OpenAI Client to Local LLM
client = OpenAI(
    base_url="http://model-runner.docker.internal/engines/llama.cpp/v1",
    api_key="not-needed"
)

# Wikipedia API Client
wiki = wikipediaapi.Wikipedia(
    language='en',
    extract_format=wikipediaapi.ExtractFormat.WIKI,
    user_agent="NOVA/1.0 (jayanthkopparthi595@gmail.com)"
)

# Assistant Persona
CHAT_SYSTEM_PROMPT = """You are NOVA, a highly accurate, empathetic, and user-friendly personal assistant.  
- Deliver clear, concise, and accurate answers using simple, accessible language to ensure broad understanding.  
- For informational queries, rely on verified, up-to-date facts from reliable sources, avoiding speculation or unconfirmed information.  
- For task-oriented queries, provide detailed, step-by-step guidance with practical, relevant examples tailored to the user's context.  
- If a query is unclear or ambiguous, ask a specific, concise clarifying question to align the response with the user's intent.  
- Use the current date and time, {current_time}, to provide accurate, time-sensitive responses when relevant.  
- Format responses in properly spaced text with appropriate line breaks for readability.
- Use universally supported emojis (e.g., ‚úÖ, ‚ùì) sparingly and with proper spacing for clarity and approachability.  
- Verify all URLs included in responses to ensure they are valid, secure (HTTPS), and directly relevant to the query.  
- If uncertain about a fact or unable to verify information, acknowledge the limitation transparently and recommend trusted sources (e.g., official websites, academic resources) for further details.  
- Avoid fabricating details, making assumptions beyond the provided context, or including irrelevant information.  
- Structure responses using clean markdown syntax with proper spacing:  
  - Use proper line breaks (\\n) for new lines
  - Use bullet points for lists with proper indentation
  - Use headings (e.g., #, ##) for clear section organization
  - Ensure all text is properly spaced between words
- Prioritize readability by using concise sentences, avoiding technical jargon unless necessary, and explaining terms when used.  
"""

WEB_SEARCH_SYSTEM_PROMPT = """You are NOVA, an expert research assistant focused on delivering accurate and reliable information.
- Summarize information from provided sources (e.g., web results, Wikipedia) into a concise, coherent response.
- Prioritize credible sources, citing them clearly (e.g., "Wikipedia states..." or "A web source from [site] reports...").
- Include key facts, dates, definitions, or notable controversies, avoiding unnecessary details.
- If sources conflict, highlight discrepancies and provide a balanced summary.
- Verify all URLs for accessibility and relevance before including them.
- If no reliable sources are found, state this clearly and suggest alternative ways to find information.
- Stay up-to-date with {current_time} for time-sensitive queries.
- Structure responses with clear sections (e.g., "Key Facts," "Sources") for readability.
- Never invent facts, sources, or details. If data is incomplete, acknowledge it.
- Ensure all text has proper spacing between words and proper formatting.
"""

# URL Regex & Checker
url_pattern = re.compile(r'https?://[\w\-./?=&%]+', re.IGNORECASE)

async def check_url(url: str) -> str:
    if url.lower().startswith("javascript:"):
        return f"{url} (unsafe)"
    try:
        async with httpx.AsyncClient(timeout=5.0, follow_redirects=True) as client:
            r = await client.get(url, headers={"User-Agent": "NOVA/1.0"})
            return f"{url} (accessible)" if r.status_code == 200 else f"{url} (status {r.status_code})"
    except Exception as e:
        return f"{url} ({e.__class__.__name__})"

# Chat Endpoint with Memory
@app.post("/chat")
async def chat_stream(request: ChatRequest) -> StreamingResponse:
    current_time = datetime.now().strftime("%B %d, %Y, %I:%M %p %Z")
    session_id = request.session_id or f"sess_{int(datetime.now().timestamp())}_{os.urandom(4).hex()}"

    history = load_conversation(session_id)

    async def event_generator() -> AsyncGenerator[str, None]:
        try:
            accumulated_response = ""
            messages = [
                {"role": "system", "content": CHAT_SYSTEM_PROMPT.format(current_time=current_time)}
            ] + history + [
                {"role": "user", "content": request.message}
            ]

            stream = client.chat.completions.create(
                model="ai/gemma3",
                messages=messages,
                stream=True,
                temperature=0.7,
                max_tokens=2048
            )

            word_buffer = ""
            
            for chunk in stream:
                if chunk.choices[0].delta.content:
                    content = chunk.choices[0].delta.content
                    word_buffer += content
                    accumulated_response += content
                    
                    # Log raw chunk
                    logger.debug(f"Raw chunk: {repr(content)}")
                    
                    # Send raw chunk without formatting
                    if re.search(r'[ \n.!?;:]', word_buffer) and not re.search(r'[A-Za-z0-9]$', word_buffer):
                        logger.debug(f"Sending chunk: {repr(word_buffer)}")
                        yield f"data: {word_buffer}\n\n"
                        word_buffer = ""
            
            # Send any remaining content
            if word_buffer.strip():
                logger.debug(f"Sending final chunk: {repr(word_buffer)}")
                yield f"data: {word_buffer}\n\n"

            # Use raw accumulated response
            final_response = accumulated_response
            logger.debug(f"Final response: {repr(final_response)}")

            urls = url_pattern.findall(final_response)
            if urls:
                yield f"data: \n\nüîó Links found:\n"
                for url in urls:
                    yield f"data: {await check_url(url)}\n"

            save_message(session_id, "user", request.message)
            save_message(session_id, "assistant", final_response)

            yield f"data: \n\n‚úÖ Continue this chat with session ID: `{session_id}`\n\n"

        except Exception as e:
            error_msg = f"Error: {str(e)}"
            logger.error(f"Stream error: {error_msg}")
            yield f"data: {error_msg}\n\n"
            save_message(session_id, "assistant", f"[System error: {str(e)}]")

    return StreamingResponse(event_generator(), media_type="text/event-stream")

# Web Search with Memory
@app.post("/web_search")
async def web_search(request: ChatRequest) -> StreamingResponse:
    current_time = datetime.now().strftime("%B %d, %Y, %I:%M %p %Z")
    query = request.message
    session_id = request.session_id or f"sess_{int(datetime.now().timestamp())}_{os.urandom(4).hex()}"

    history = load_conversation(session_id)

    async def event_generator() -> AsyncGenerator[str, None]:
        try:
            summary_prompt = WEB_SEARCH_SYSTEM_PROMPT.format(current_time=current_time) + "\n\nAnalyze and summarize the following sources:\n\n"
            all_urls = []

            try:
                dd_results = DDGS().text(query, max_results=5)
                if dd_results:
                    summary_prompt += "=== Web Results (DuckDuckGo) ===\n"
                    for i, r in enumerate(dd_results, 1):
                        summary_prompt += f"{i}. [{r['title']}]({r['href']})\n   {r['body']}\n\n"
                        all_urls.append(r['href'])
            except Exception as e:
                summary_prompt += f"‚ö†Ô∏è Could not fetch web results: {str(e)}\n\n"

            try:
                wiki_page = wiki.page(query)
                if wiki_page.exists():
                    summary_prompt += f"=== Wikipedia Entry: {wiki_page.title} ===\n{wiki_page.summary[:1200]}{'...' if len(wiki_page.summary) > 1200 else ''}\n\n"
                    all_urls.append(wiki_page.fullurl)
                else:
                    summary_prompt += f"‚ö†Ô∏è No Wikipedia page found for '{query}'.\n\n"
            except Exception as e:
                summary_prompt += f"‚ö†Ô∏è Error fetching Wikipedia: {str(e)}\n\n"

            if "‚ö†Ô∏è Could not fetch" in summary_prompt and "=== Wikipedia Entry" not in summary_prompt:
                response = f"‚öå No reliable information found for *{query}* as of {current_time}. Try a different phrasing."
                logger.debug(f"No search results: {repr(response)}")
                yield f"data: {response}\n\n"
                save_message(session_id, "user", query)
                save_message(session_id, "assistant", response)
                yield f"data: \n\nüìå Tip: Be specific and use full terms (e.g., 'climate change effects on oceans').\n"
                yield f"data: ‚úÖ Use session ID: `{session_id}` to continue.\n\n"
                return

            context_messages = [
                {"role": "system", "content": summary_prompt},
                {"role": "user", "content": f"Summarize the key facts about: {query}"}
            ] + history[-4:]

            stream = client.chat.completions.create(
                model="ai/gemma3",
                messages=context_messages,
                stream=True,
                temperature=0.7,
                max_tokens=2048
            )

            accumulated_response = ""
            word_buffer = ""
            
            for chunk in stream:
                if chunk.choices[0].delta.content:
                    content = chunk.choices[0].delta.content
                    word_buffer += content
                    accumulated_response += content
                    
                    # Log raw chunk
                    logger.debug(f"Raw chunk: {repr(content)}")
                    
                    # Send raw chunk without formatting
                    if re.search(r'[ \n.!?;:]', word_buffer) and not re.search(r'[A-Za-z0-9]$', word_buffer):
                        logger.debug(f"Sending chunk: {repr(word_buffer)}")
                        yield f"data: {word_buffer}\n\n"
                        word_buffer = ""
            
            # Send any remaining content
            if word_buffer.strip():
                logger.debug(f"Sending final chunk: {repr(word_buffer)}")
                yield f"data: {word_buffer}\n\n"

            # Use raw accumulated response
            final_response = accumulated_response
            logger.debug(f"Final response: {repr(final_response)}")

            if all_urls:
                yield f"data: \n\nüîó Verified Sources:\n"
                for url in all_urls:
                    yield f"data: {await check_url(url)}\n"

            yield f"data: \n\nüí° You can ask follow-up questions to go deeper!\n"
            yield f"data: ‚úÖ Continue with session ID: `{session_id}`\n\n"

            save_message(session_id, "user", query)
            save_message(session_id, "assistant", final_response)

        except Exception as e:
            error_msg = f"Search failed: {str(e)}"
            logger.error(f"Search error: {error_msg}")
            yield f"data: {error_msg}\n\n"
            save_message(session_id, "user", query)
            save_message(session_id, "assistant", f"[Error: {str(e)}]")

    return StreamingResponse(event_generator(), media_type="text/event-stream")

# Session Management Endpoints
@app.get("/sessions")
async def list_sessions():
    with sqlite3.connect(DB_PATH) as conn:
        conn.row_factory = sqlite3.Row
        cur = conn.cursor()
        cur.execute("SELECT DISTINCT session_id FROM conversations ORDER BY timestamp")
        sessions = [row["session_id"] for row in cur.fetchall()]
    return {"sessions": sessions}

@app.get("/sessions/{session_id}")
async def get_session(session_id: str):
    with sqlite3.connect(DB_PATH) as conn:
        conn.row_factory = sqlite3.Row
        cur = conn.cursor()
        cur.execute(
            "SELECT role, content, timestamp FROM conversations WHERE session_id = ? ORDER BY timestamp",
            (session_id,)
        )
        rows = cur.fetchall()
        if not rows:
            raise HTTPException(status_code=404, detail="Session not found")
        return {
            "session_id": session_id,
            "messages": [{"role": r["role"], "content": r["content"], "time": r["timestamp"]} for r in rows]
        }

@app.delete("/sessions/{session_id}")
async def delete_session(session_id: str):
    with sqlite3.connect(DB_PATH) as conn:
        cur = conn.cursor()
        cur.execute("SELECT COUNT(*) FROM conversations WHERE session_id = ?", (session_id,))
        count = cur.fetchone()[0]
        if count == 0:
            raise HTTPException(status_code=404, detail="Session not found")
        cur.execute("DELETE FROM conversations WHERE session_id = ?", (session_id,))
        conn.commit()
    return {"message": f"Session {session_id} deleted successfully"}

# Health Check
@app.get("/")
async def root():
    return {"message": "NOVA Assistant is running", "endpoints": ["/chat", "/web_search", "/sessions"]}