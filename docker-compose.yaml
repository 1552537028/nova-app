version: "3.9"

services:
  ai-app:
    image: docker.io/jayanthkopparthi/cloud_app-ai-app:latest
    container_name: nova-ai
    ports:
      - "8000:8000"
    depends_on:
      - llm
    environment:
      - OPENAI_API_KEY=not-needed   # not used for local LLM
    networks:
      - nova-net

  llm:
    image: ghcr.io/ggerganov/llama.cpp:server  # llama.cpp server image
    container_name: nova-llm
    command: ["--model", "/models/gemma3.bin", "--host", "0.0.0.0", "--port", "8080"]
    volumes:
      - ./models:/models   # put your model weights in ./models
    ports:
      - "8080:8080"
    networks:
      - nova-net

networks:
  nova-net:
    driver: bridge
